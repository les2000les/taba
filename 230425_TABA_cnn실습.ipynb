{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfmJ+YQDUBjOA0IAW+eTT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/les2000les/taba/blob/main/230425_TABA_cnn%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST"
      ],
      "metadata": {
        "id": "0iAOdm9JEsum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "h-cg8SHiDckm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu 되는지 확인\n",
        "torch.cuda.is_available() #시스템에서 cuda지원해서 pytorch 사용 가능능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJymRvgAD7Yi",
        "outputId": "c5a563fc-85aa-49ad-a56d-0f761232dee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "G5oPCc7DElfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset 다운로드드\n",
        "train_dataset = MNIST(root = 'MNIST_data/', train = True, transform = transforms.ToTensor(), download = True) #가져올 때 totensor() 적용\n",
        "test_dataset = MNIST(root = 'MNIST_data/', train = False, transform = transforms.ToTensor(), download = True) #가져올 때 totensor() 적용"
      ],
      "metadata": {
        "id": "NmRUcSDDEydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm46goF7FJgy",
        "outputId": "4b9c4e9d-bf9e-4b14-e721-f63693fa56e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: MNIST_data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader 생성\n",
        "\n",
        "train_loader  = DataLoader(dataset = train_dataset, batch_size = 128, shuffle = True)\n",
        "test_loader  = DataLoader(dataset = test_dataset, batch_size = 128, shuffle = True)\n",
        "# 데이터를 꺼내오는 로더를 선언하는데 한 번에 128개의 이미지를 꺼내고, 셔플을 통해 랜덤으로 가져옴옴"
      ],
      "metadata": {
        "id": "N0ZQiQA_FfeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor"
      ],
      "metadata": {
        "id": "ayg4L3LSGCLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# totensor: tensor로 변환\n",
        "# tensor는 파이토치 기준으로 텐서로 변환시켜야 연산 가능\n",
        "# aaa = [0, 0, 0]\n",
        "# numpy로 만들었을 때 연산 불가 텐서로 변환 필요"
      ],
      "metadata": {
        "id": "OTEfUxAyFvKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy > Tensor\n",
        "\n",
        "z = torch.empty(5,2)\n",
        "print(z)\n",
        "print(z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqTiJFWrGX-w",
        "outputId": "21784580-d2f6-495a-8dfb-d9f67b5e60e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3452e-43,  0.0000e+00],\n",
            "        [ 9.1084e-44,  0.0000e+00],\n",
            "        [ 2.7354e-33,  0.0000e+00],\n",
            "        [-2.7487e-34,  0.0000e+00],\n",
            "        [ 4.4842e-44,  0.0000e+00]])\n",
            "torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones([5,2])\n",
        "print(a)\n",
        "print(a.shape)\n",
        "\n",
        "\n",
        "#tensor로 변환\n",
        "b = torch.from_numpy(a)\n",
        "print(b, b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAqKF8MpGeyp",
        "outputId": "b2669947-5571-4fe3-cba3-216ed20bd375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "(5, 2)\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], dtype=torch.float64) torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor > numpy\n",
        "\n",
        "numpy_arr = b.numpy()\n",
        "print(numpy_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NooWFAy7HAAP",
        "outputId": "9b94199d-790d-4ac3-e053-d118810dd5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MNIST 데이터셋을 확인"
      ],
      "metadata": {
        "id": "OHnXRXCZHP55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_dataset[0][0].numpy()\n",
        "plt.imshow(img[0], cmap ='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "drgKgmqAHRmX",
        "outputId": "ce3c27a2-a0b7-46d4-f296-8effc4152b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd027c56a0>"
            ]
          },
          "metadata": {},
          "execution_count": 307
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##모델만들기(multi layer perceptron)"
      ],
      "metadata": {
        "id": "bdtB-vp_Huar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sequential\n",
        "mnist_fc_model = nn.Sequential(\n",
        "    nn.Flatten(), #한 줄로 펴줌\n",
        "    nn.Linear(in_features = 28*28*1, out_features = 256),\n",
        "    nn.Sigmoid(), #활성화 함수\n",
        "    nn.Linear(in_features = 256, out_features = 10),\n",
        "    #in_feature를 잘 맞춰줘야함\n",
        "    nn.Softmax() #총합이 1이 되도록 해주는 기능\n",
        ")"
      ],
      "metadata": {
        "id": "m7EX2yLYHVT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cuda\"\n",
        "# 모델을 device로 전달해야 함\n",
        "# cpu에 만들어지까 gpu로 넘겨서 연산을 하도록 해야함\n",
        "mnist_fc_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeWySCfPIesf",
        "outputId": "e251d911-f7b2-4848-83aa-ec3d9130604a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (2): Sigmoid()\n",
              "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (4): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "import time\n",
        "def train(model, train_loader):\n",
        "  epochs = 10 # 데이터를 보는 횟수\n",
        "  optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
        "  criterion = nn.CrossEntropyLoss() #클래스분류에서 자주 사용하는 loss\n",
        "\n",
        "\n",
        "\n",
        "  start_time = time.time() #시작시간 체크\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    #model 학습이 가능하도록 모드를 변경\n",
        "    model.train()\n",
        "    print(f\"epochs: {str(epoch+1)} / {str(epochs)}\")\n",
        "\n",
        "    for samples in train_loader:  #trainloader에서 128개씩 던져줌\n",
        "       x_t, y_t = samples\n",
        "       x_t, y_t = x_t.to(device), y_t.to(device) #데이터를 gpu로 보냄\n",
        "       pred = model(x_t) #predict\n",
        "       loss = criterion(pred, y_t) #loss 구하기\n",
        "       #optimizer을 사용해서 학습을 시킴\n",
        "       optimizer.zero_grad() #gradient가 0이 되도록 초기화\n",
        "       #역전파\n",
        "       loss.backward() #기울기(gradient) 구하기\n",
        "       optimizer.step() #기울기 적용\n",
        "\n",
        "    ##학습은 여기까지\n",
        "    #하나의 epoch에 대해 학습이 끝난 후 train에 대한 정확도 test \n",
        "    \n",
        "    #모델을 평가상태로 모드 변경\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for sample in train_loader:\n",
        "      xx,yy = samples\n",
        "      xx, yy = xx.to(device), yy.to(device)\n",
        "      pred = model(xx) # 모델 predict\n",
        "      _, predicted = torch.max(pred, 1)\n",
        "      correct += predicted.eq(yy.data).sum()\n",
        "    print(f\"train_accuracy: {(100*correct/len(train_loader.dataset)).item()}.\")\n",
        "\n",
        "    end_time = time.time() #끝나는 시간 확인\n",
        "\n",
        "    지난시간 = end_time - start_time\n",
        "    분 = int(지난시간 // 60)\n",
        "    초 = int(지난시간 % 60)\n",
        "\n",
        "    print(f\"경과시간: {분}분 {초}초\")"
      ],
      "metadata": {
        "id": "iXe6M1IJIkcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(mnist_fc_model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "epOXoRdrK-Q0",
        "outputId": "abf5cad9-1df1-42f0-f5e3-2f64302c0d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-311-a78dfe5c3f4f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_fc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-310-b63596b13b16>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epochs: {str(epoch+1)} / {str(epochs)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#trainloader에서 128개씩 던져줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m        \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#데이터를 gpu로 보냄\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0m__array_interface__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##우리가 만든 모델의 복잡도 알아보기"
      ],
      "metadata": {
        "id": "ZLgwTE-LnBsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 파라미터 수로 복잡도 판단\n",
        "#훈련 가능한 parameter\n",
        "#훈련 가능하지 않은 parameter"
      ],
      "metadata": {
        "id": "2OIIZWyeMJgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def 복잡도계산(model):\n",
        "  pp = 0\n",
        "  # 모델에서 parameter를 하나씩 불러옴\n",
        "  for p in list(model.parameters()):\n",
        "    nn = 1\n",
        "    # 각 parameter의 수를 더해줌\n",
        "    for s in list(p.size()):\n",
        "      nn = nn*s\n",
        "    pp += nn\n",
        "  return pp"
      ],
      "metadata": {
        "id": "umcuKsIVnOJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "복잡도계산(mnist_fc_model)"
      ],
      "metadata": {
        "id": "A58gVlXTn0pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN을 이용해서 모델 설계"
      ],
      "metadata": {
        "id": "DfnRE0RToLXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn 합성곱연산을 이용한 모델\n",
        "# 이미지에서 많이 사용됨"
      ],
      "metadata": {
        "id": "RHj7idceoAoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_cnn_model = nn.Sequential(\n",
        "    #input = 1*28*28\n",
        "    nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = 3, stride = 1, padding = 0),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 3, stride = 1, padding = 0),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # convolution layer 2개 완성\n",
        "    nn.Flatten(), #한 줄로 펴줌\n",
        "    nn.Linear(in_features = 24*24*8, out_features = 48),\n",
        "    nn.Sigmoid(), #활성화 함수\n",
        "    nn.Linear(in_features = 48, out_features = 10),\n",
        "    #in_feature를 잘 맞춰줘야함\n",
        "    nn.Softmax() #총합이 1이 되도록 해주는 기능\n",
        ")"
      ],
      "metadata": {
        "id": "R079cthLoita"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "복잡도계산(mnist_cnn_model)"
      ],
      "metadata": {
        "id": "FKfnOEerpgMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_cnn_model.to(device)\n",
        "train(mnist_cnn_model, train_loader)"
      ],
      "metadata": {
        "id": "u-qTd-xVprId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Le-Net"
      ],
      "metadata": {
        "id": "k3SwB0caq8MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Le-Net이라는 검증된 네트워크를 만들거임"
      ],
      "metadata": {
        "id": "t275Tzbpql4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "lenet = nn.Sequential(\n",
        "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, stride = 1),\n",
        "    nn.Tanh(),\n",
        "    nn.AvgPool2d(kernel_size = 2),\n",
        "    nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, stride = 1),\n",
        "    nn.Tanh(),\n",
        "    nn.AvgPool2d(kernel_size = 2),\n",
        "    nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 4, stride = 1),\n",
        "    nn.Tanh(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(in_features = 120, out_features = 84),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(in_features = 84, out_features = 10),\n",
        "    nn.Softmax()\n",
        ")\n"
      ],
      "metadata": {
        "id": "EutXIECMrBcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "복잡도계산(lenet)"
      ],
      "metadata": {
        "id": "hi0Hb7_mrEYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.to(device)\n",
        "train(lenet, train_loader)"
      ],
      "metadata": {
        "id": "gcgyrn4dstPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(lenet, input_size = (1, 28, 28)) "
      ],
      "metadata": {
        "id": "i1NFRgl2szH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(mnist_cnn_model, input_size = (1, 28, 28))"
      ],
      "metadata": {
        "id": "072q5pDFtawZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear,\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "id": "br9VcHZhttn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#복잡한 CNN"
      ],
      "metadata": {
        "id": "OgxpwSQd4zPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FashionMNIST"
      ],
      "metadata": {
        "id": "AmnJQtf932g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "uZ5e2tP736QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(), #tensor 형태로 변환\n",
        "    transforms.Resize(48) # 48x 48이미지로 변환\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = FashionMNIST('./', transform = fashion_mnist_transforms, train = True, download = True)\n",
        "test_dataset = FashionMNIST('./', transform = fashion_mnist_transforms, train = False, download = True)\n",
        "\n",
        "\n",
        "\n",
        "train_loader =  DataLoader(dataset = train_dataset,batch_size = 256, shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = 256, shuffle = True)"
      ],
      "metadata": {
        "id": "q1yqUS7u4AHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델만들기"
      ],
      "metadata": {
        "id": "sMNNW0065muK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 총 7개의 convolution layer가 존재하도록 만들 것"
      ],
      "metadata": {
        "id": "7kPJP2fQ4h9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "class SimpleConvNet1(nn.Module):\n",
        "  def __init__(self):\n",
        "    #초기화\n",
        "    super().__init__() #부모 클래스 초기화\n",
        "    #선언\n",
        "    self.CNN = nn.Sequential(\n",
        "        #stage1\n",
        "        nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "        \n",
        "        \n",
        "        #stage2\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "\n",
        "        #stage3\n",
        "        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 'same'),\n",
        "        nn.ReLU(True),\n",
        "        nn.MaxPool2d(kernel_size = 4, stride = 4), #크기를 많이 줄이기 위해\n",
        "        )\n",
        "    \n",
        "    self.FC = nn.Sequential(\n",
        "      nn.Linear(64*3*3, 256),\n",
        "      nn.ReLU(True),\n",
        "      nn.Dropout(p = 0.2),\n",
        "      nn.Linear(256, 10),\n",
        "      nn.Softmax()\n",
        "      )\n",
        "\n",
        "  #forward\n",
        "  def forward(self, inp) : \n",
        "    cnn_result = self.CNN(inp)\n",
        "    flatten = torch.flatten(cnn_result, 1)\n",
        "    fc_result = self.FC(flatten)\n",
        "    return fc_result"
      ],
      "metadata": {
        "id": "ZW1cowyM5qr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet1 = SimpleConvNet1()"
      ],
      "metadata": {
        "id": "h7TvO18y98Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet1.to(device)\n",
        "summary(convnet1,(1, 48, 48))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_QyMoCL-NLJ",
        "outputId": "d4e484e1-2887-49d6-d035-81b50738f109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 48, 48]             160\n",
            "              ReLU-2           [-1, 16, 48, 48]               0\n",
            "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
            "              ReLU-4           [-1, 16, 48, 48]               0\n",
            "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
            "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
            "              ReLU-7           [-1, 32, 24, 24]               0\n",
            "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
            "              ReLU-9           [-1, 32, 24, 24]               0\n",
            "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
            "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
            "             ReLU-12           [-1, 64, 12, 12]               0\n",
            "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-14           [-1, 64, 12, 12]               0\n",
            "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-16           [-1, 64, 12, 12]               0\n",
            "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
            "           Linear-18                  [-1, 256]         147,712\n",
            "             ReLU-19                  [-1, 256]               0\n",
            "          Dropout-20                  [-1, 256]               0\n",
            "           Linear-21                   [-1, 10]           2,570\n",
            "          Softmax-22                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 259,002\n",
            "Trainable params: 259,002\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.23\n",
            "Params size (MB): 0.99\n",
            "Estimated Total Size (MB): 3.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##print(train_dataset[0][0])\n",
        "print(train_dataset[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJH4JiLf6gMw",
        "outputId": "1c36c49c-aa03-4b39-f59b-c4a8337d69ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 48, 48])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(convnet1, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI-2z9X_6h0T",
        "outputId": "eac9d41e-22f9-4f34-f031-83a564114260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs: 1 / 10\n",
            "train_accuracy: 26.633333206176758.\n",
            "경과시간: 0분 32초\n",
            "epochs: 2 / 10\n",
            "train_accuracy: 27.808334350585938.\n",
            "경과시간: 1분 8초\n",
            "epochs: 3 / 10\n",
            "train_accuracy: 29.766666412353516.\n",
            "경과시간: 1분 45초\n",
            "epochs: 4 / 10\n",
            "train_accuracy: 30.55000114440918.\n",
            "경과시간: 2분 28초\n",
            "epochs: 5 / 10\n",
            "train_accuracy: 28.200000762939453.\n",
            "경과시간: 3분 4초\n",
            "epochs: 6 / 10\n",
            "train_accuracy: 30.941667556762695.\n",
            "경과시간: 3분 47초\n",
            "epochs: 7 / 10\n",
            "train_accuracy: 28.983333587646484.\n",
            "경과시간: 4분 20초\n",
            "epochs: 8 / 10\n",
            "train_accuracy: 29.375.\n",
            "경과시간: 5분 0초\n",
            "epochs: 9 / 10\n",
            "train_accuracy: 28.59166717529297.\n",
            "경과시간: 5분 58초\n",
            "epochs: 10 / 10\n",
            "train_accuracy: 29.766666412353516.\n",
            "경과시간: 6분 35초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##test 하는 함수"
      ],
      "metadata": {
        "id": "SyVcsdUAEVkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader):\n",
        "  with torch.no_grad():\n",
        "    #이 안에 있는 것들은 기울기 계산을 안함\n",
        "    #모델이 고정됨. 평가하는 용도로 제격\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for xx, yy in loader:\n",
        "      #xx 데이터(이미지),\n",
        "      # yy 정답\n",
        "      data,target = xx.to(device), yy.to(device)\n",
        "      pred = model(data)\n",
        "      _, predicted = torch.max(pred, 1)\n",
        "      correct += predicted.eq(target.data).sum()\n",
        "\n",
        "      \n",
        "\n",
        "    print(f\"test accuracy: {(100 * correct /len(loader.dataset)).item()}\")"
      ],
      "metadata": {
        "id": "Vh7tg1PAAdbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(convnet1, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPYjQjqAFOom",
        "outputId": "1635c8ee-de3b-4296-b8a2-a2bdc3302c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 83.04000091552734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST 훈련"
      ],
      "metadata": {
        "id": "8W8jZtMUJ2eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVHN이라는 데이터셋 학습"
      ],
      "metadata": {
        "id": "mnFQ1AJnJ4qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(), #tensor 형태로 변환\n",
        "    transforms.Resize(48) # 48x 48이미지로 변환\n",
        "])"
      ],
      "metadata": {
        "id": "OOJgh1kYSGKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(root = 'MNIST_data/', train = True, transform = fashion_mnist_transforms, download = True)\n",
        "test_dataset = MNIST(root = 'MNIST_data/', train = False, transform = fashion_mnist_transforms, download = True)"
      ],
      "metadata": {
        "id": "uldNdzQ7FVGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 256, shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = 256, shuffle = True)"
      ],
      "metadata": {
        "id": "6kHYrLVkKKH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet2 = SimpleConvNet1()"
      ],
      "metadata": {
        "id": "4LqGhONFKXup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convnet2.to(device)\n",
        "summary(convnet2, (1, 48, 48))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNOeSpeQKbjY",
        "outputId": "8cdb716f-0e50-4375-802b-43b25b836ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 48, 48]             160\n",
            "              ReLU-2           [-1, 16, 48, 48]               0\n",
            "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
            "              ReLU-4           [-1, 16, 48, 48]               0\n",
            "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
            "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
            "              ReLU-7           [-1, 32, 24, 24]               0\n",
            "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
            "              ReLU-9           [-1, 32, 24, 24]               0\n",
            "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
            "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
            "             ReLU-12           [-1, 64, 12, 12]               0\n",
            "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-14           [-1, 64, 12, 12]               0\n",
            "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-16           [-1, 64, 12, 12]               0\n",
            "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
            "           Linear-18                  [-1, 256]         147,712\n",
            "             ReLU-19                  [-1, 256]               0\n",
            "          Dropout-20                  [-1, 256]               0\n",
            "           Linear-21                   [-1, 10]           2,570\n",
            "          Softmax-22                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 259,002\n",
            "Trainable params: 259,002\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.23\n",
            "Params size (MB): 0.99\n",
            "Estimated Total Size (MB): 3.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(convnet2, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a-8UN9CKgnl",
        "outputId": "d3ee95f5-eeae-4591-9212-5a58d9960960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs: 1 / 10\n",
            "train_accuracy: 29.766666412353516.\n",
            "경과시간: 0분 32초\n",
            "epochs: 2 / 10\n",
            "train_accuracy: 34.07500076293945.\n",
            "경과시간: 1분 5초\n",
            "epochs: 3 / 10\n",
            "train_accuracy: 36.03333282470703.\n",
            "경과시간: 1분 38초\n",
            "epochs: 4 / 10\n",
            "train_accuracy: 36.42499923706055.\n",
            "경과시간: 2분 11초\n",
            "epochs: 5 / 10\n",
            "train_accuracy: 36.81666564941406.\n",
            "경과시간: 2분 44초\n",
            "epochs: 6 / 10\n",
            "train_accuracy: 36.81666564941406.\n",
            "경과시간: 3분 17초\n",
            "epochs: 7 / 10\n",
            "train_accuracy: 36.81666564941406.\n",
            "경과시간: 3분 51초\n",
            "epochs: 8 / 10\n",
            "train_accuracy: 36.81666564941406.\n",
            "경과시간: 4분 23초\n",
            "epochs: 9 / 10\n",
            "train_accuracy: 36.81666564941406.\n",
            "경과시간: 4분 57초\n",
            "epochs: 10 / 10\n",
            "train_accuracy: 37.20833206176758.\n",
            "경과시간: 5분 30초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "svhn_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(48),\n",
        "    transforms.Grayscale(),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "SVHN_train_dataset = datasets.SVHN(root = './', split='train', transform=svhn_transform, download = True)\n",
        "SVHN_test_dataset = datasets.SVHN(root = './', split='test', transform=svhn_transform, download = True)\n",
        "\n",
        "sv_train_loader = DataLoader(dataset=SVHN_train_dataset, batch_size = 128, shuffle  = True)\n",
        "sv_test_loader = DataLoader(dataset=SVHN_test_dataset, batch_size = 128, shuffle  = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRWKh4qFLPxX",
        "outputId": "3f9f06b9-5090-44db-9791-4484eb613a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./train_32x32.mat\n",
            "Using downloaded and verified file: ./test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVHN_train_dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3aePgEHNe7H",
        "outputId": "cf68f90b-a51b-49ed-9e37-be5f79e1bfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(SVHN_train_dataset[170][0][0], cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "GItUdKXdNmmT",
        "outputId": "51bbcb4a-0ff1-4c93-d899-c200f22b9a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(convnet2, sv_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgUmi40iNyRx",
        "outputId": "3fd2358e-70f0-4039-eeec-5f36721728fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 12.40012264251709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer learning"
      ],
      "metadata": {
        "id": "7p-XYdhPOEl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convnet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNhJ4I-_OAPI",
        "outputId": "00e45638-a374-4c6b-c30c-f3ba0e3d1e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleConvNet1(\n",
              "  (CNN): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (FC): Sequential(\n",
              "    (0): Linear(in_features=576, out_features=256, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
              "    (4): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SvhnNet(nn.Module):\n",
        "  def __init__(self, pretrain_model):\n",
        "    super().__init__()\n",
        "    self.pretrain = pretrain_model # 학습된 모델을 self.pretrain에 저장\n",
        "    #우리가 받은 pretrain_model의 parameter를 고정\n",
        "    for param in self.pretrain.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "    self.add_model = nn.Sequential(\n",
        "        nn.Linear(in_features = 64 *3 * 3, out_features = 256),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(p = 0.2),\n",
        "        nn.Linear(in_features = 256, out_features = 10),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, inp):\n",
        "    with torch.no_grad():\n",
        "      cnn_result = self.pretrain(inp)\n",
        "    flatten = torch.flatten(cnn_result, 1)\n",
        "    result = self.add_model(flatten)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "-F6zwNl-OHxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svhn_net = SvhnNet(convnet2.CNN)"
      ],
      "metadata": {
        "id": "jtclBsC4Ob9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svhn_net.to(device)\n",
        "summary(svhn_net, (1, 48,48))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNnQMCNJQIz4",
        "outputId": "cb1be316-6182-4010-94d6-146db420069f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 48, 48]             160\n",
            "              ReLU-2           [-1, 16, 48, 48]               0\n",
            "            Conv2d-3           [-1, 16, 48, 48]           2,320\n",
            "              ReLU-4           [-1, 16, 48, 48]               0\n",
            "         MaxPool2d-5           [-1, 16, 24, 24]               0\n",
            "            Conv2d-6           [-1, 32, 24, 24]           4,640\n",
            "              ReLU-7           [-1, 32, 24, 24]               0\n",
            "            Conv2d-8           [-1, 32, 24, 24]           9,248\n",
            "              ReLU-9           [-1, 32, 24, 24]               0\n",
            "        MaxPool2d-10           [-1, 32, 12, 12]               0\n",
            "           Conv2d-11           [-1, 64, 12, 12]          18,496\n",
            "             ReLU-12           [-1, 64, 12, 12]               0\n",
            "           Conv2d-13           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-14           [-1, 64, 12, 12]               0\n",
            "           Conv2d-15           [-1, 64, 12, 12]          36,928\n",
            "             ReLU-16           [-1, 64, 12, 12]               0\n",
            "        MaxPool2d-17             [-1, 64, 3, 3]               0\n",
            "           Linear-18                  [-1, 256]         147,712\n",
            "             ReLU-19                  [-1, 256]               0\n",
            "          Dropout-20                  [-1, 256]               0\n",
            "           Linear-21                   [-1, 10]           2,570\n",
            "          Softmax-22                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 259,002\n",
            "Trainable params: 150,282\n",
            "Non-trainable params: 108,720\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.23\n",
            "Params size (MB): 0.99\n",
            "Estimated Total Size (MB): 3.22\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVHN_train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D91OMgoGW7cV",
        "outputId": "be4e624e-807a-40af-b5fa-a096b813ee82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset SVHN\n",
              "    Number of datapoints: 73257\n",
              "    Root location: ./\n",
              "    Split: train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Resize(size=48, interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               Grayscale(num_output_channels=1)\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋에서 일부만 가져오기\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "svhn_train_1, svhn_train_2 =random_split(SVHN_train_dataset, [100, 73157])\n",
        "sv_train_loader_2 = DataLoader(dataset= svhn_train_1, batch_size = 128, shuffle = True)"
      ],
      "metadata": {
        "id": "XN0W9bVHQdCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(svhn_net, sv_train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "3UgINDZ2QXCp",
        "outputId": "558cd267-b5f2-4a79-8809-1e9666510534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs: 1 / 10\n",
            "train_accuracy: 14.861377716064453.\n",
            "경과시간: 1분 10초\n",
            "epochs: 2 / 10\n",
            "train_accuracy: 11.732666969299316.\n",
            "경과시간: 2분 22초\n",
            "epochs: 3 / 10\n",
            "train_accuracy: 17.207910537719727.\n",
            "경과시간: 3분 38초\n",
            "epochs: 4 / 10\n",
            "train_accuracy: 17.990089416503906.\n",
            "경과시간: 4분 52초\n",
            "epochs: 5 / 10\n",
            "train_accuracy: 22.683156967163086.\n",
            "경과시간: 6분 4초\n",
            "epochs: 6 / 10\n",
            "train_accuracy: 20.33662223815918.\n",
            "경과시간: 7분 40초\n",
            "epochs: 7 / 10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-400-f566405db63a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msv_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-310-b63596b13b16>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epochs: {str(epoch+1)} / {str(epochs)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#trainloader에서 128개씩 던져줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m        \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m        \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#데이터를 gpu로 보냄\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/svhn.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mget_image_num_channels\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"getbands\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36m_is_pil_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0maccimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet 18을 이용해서 매우 적은 숫자의 fashionMnist학습"
      ],
      "metadata": {
        "id": "ISAYsMlMYVWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(224),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = FashionMNIST(root = './', transform=fashion_mnist_transforms, train = True, download = True)\n",
        "test_dataset = FashionMNIST(root = './', transform=fashion_mnist_transforms, train = False, download = True)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size = 128, shuffle  = True)"
      ],
      "metadata": {
        "id": "lDpb3pBVVJXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_split\n",
        "\n",
        "train_dataset1, train_dataset2 = random_split(train_dataset, [100, 59900])\n",
        "train_loader2 = DataLoader(dataset = train_dataset1, batch_size = 128, shuffle = True)"
      ],
      "metadata": {
        "id": "Ir5g_gCnZL6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학습된 resNet18을 불러오자"
      ],
      "metadata": {
        "id": "T5cSHYABZ04O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "resnet18_pretrained = models.resnet18(pretrained = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC6volkZZ0q5",
        "outputId": "8bc1c202-9c6c-4012-86f8-a7e86b6a87cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##transfer learning을 진행하기 위해 할 것\n",
        "# 1. 뒤쪽에 fc레이어를 변경\n",
        "# 2. 앞쪽에 cnn부분의 학습을 멈춤(freeze)"
      ],
      "metadata": {
        "id": "7QIgkLCUaIuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze\n",
        "for param in resnet18_pretrained.parameters():\n",
        "  param.requires_grad = False\n",
        "# 뒤쪽에 FC 레이어를 변경\n",
        "resnet18_pretrained.fc = nn.Sequential(\n",
        "    nn.Linear(512,10),\n",
        "    nn.Softmax()\n",
        ")\n",
        "resnet18_pretrained.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7,7),stride=(2,2),padding=(3,3),bias=False)\n",
        "resnet18_pretrained.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgSwybvMaWZu",
        "outputId": "e5d85037-0dc3-4119-986d-f7c6e8a60cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet18_pretrained, (1,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUViSqsBaoBl",
        "outputId": "0218cbce-3bdb-4b62-ab49-490c79749466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           3,136\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "          Softmax-69                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 11,175,370\n",
            "Trainable params: 8,266\n",
            "Non-trainable params: 11,167,104\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 105.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(resnet18_pretrained, train_loader2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPphtK7fbhtX",
        "outputId": "2d767f8b-e155-4db0-cdfd-56c448e5bae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs: 1 / 10\n",
            "train_accuracy: 26.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 2 / 10\n",
            "train_accuracy: 16.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 3 / 10\n",
            "train_accuracy: 16.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 4 / 10\n",
            "train_accuracy: 16.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 5 / 10\n",
            "train_accuracy: 13.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 6 / 10\n",
            "train_accuracy: 9.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 7 / 10\n",
            "train_accuracy: 9.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 8 / 10\n",
            "train_accuracy: 12.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 9 / 10\n",
            "train_accuracy: 13.0.\n",
            "경과시간: 0분 0초\n",
            "epochs: 10 / 10\n",
            "train_accuracy: 12.0.\n",
            "경과시간: 0분 0초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fine tuning"
      ],
      "metadata": {
        "id": "zoQCOYjUb505"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_pretrained = models.resnet18(pretrained=True)\n",
        "resnet18_pretrained.to(device)\n",
        "\n",
        "# freeze\n",
        "# for param in resnet18_pretrained.parameters():\n",
        "#   param.requires_grad = False\n",
        "# 뒤쪽에 FC 레이어를 변경\n",
        "resnet18_pretrained.fc = nn.Sequential(\n",
        "    nn.Linear(512,10),\n",
        "    nn.Softmax()\n",
        ")\n",
        "resnet18_pretrained.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3),bias=False)\n",
        "resnet18_pretrained.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFqjXYKgb6_x",
        "outputId": "39c7a36f-02e5-4bdf-c2df-05c1b8788b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 432
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(resnet18_pretrained, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33t5R07gcmQw",
        "outputId": "e3ba21d7-1185-4bd0-d5df-bf1806ef8b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 16.190000534057617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(resnet18_pretrained, input_size=(1,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg2z9RrZcmOU",
        "outputId": "cd49840c-498e-4169-82ba-04db2cb060d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           3,136\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "          Softmax-69                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 11,175,370\n",
            "Trainable params: 11,175,370\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 105.61\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWZ48nSqcmMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wM7-_0hdcmJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-o66lIgAcmHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8me1s-0rcmE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coOf1H_1cmCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}